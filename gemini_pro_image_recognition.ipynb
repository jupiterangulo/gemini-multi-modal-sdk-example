{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f936bc39-f485-48bf-9fe1-47b761ad3f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'your-project-id'\n",
    "bucket_name = 'your-gcs-bucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b435b22a-5a72-4007-96b6-1652bf5b8582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import *\n",
    "from google.cloud import storage\n",
    "from PIL import Image\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71df28e5-6bdd-4acf-a53b-eb3450df3388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30f0db7d-c974-4a96-bd7e-68c7678a5e1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(b64_image: str, prompt: str, mimeType: str) -> str:\n",
    "\n",
    "    # Create a GenerativeModel object for the specified model\n",
    "    multimodal_model = GenerativeModel(\"gemini-pro-vision\")\n",
    "\n",
    "    # Generate content using the model, passing the image and prompt\n",
    "    response = multimodal_model.generate_content(\n",
    "        [\n",
    "            Part.from_data(\n",
    "                data=b64_image, mime_type=mimeType # Use the mime_type variable\n",
    "            ),\n",
    "            Part.from_text(prompt),  # Encapsulate the prompt in a Part object\n",
    "        ]\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68317921-f993-4f39-b2e5-0295711cbc70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_image(image_bytes):\n",
    "    encoded_base_image = base64.b64encode(image_bytes)\n",
    "    B64_BASE_IMAGE = encoded_base_image.decode('utf-8')\n",
    "    return B64_BASE_IMAGE\n",
    "\n",
    "suffixes = (\".jpg\", \".jpeg\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_magic(prompt):\n",
    "    responses = []\n",
    "    file_names = []\n",
    "    mimeType = \"image/jpeg\"\n",
    "    blobs = bucket.list_blobs(prefix='raw_images/')\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(suffixes):\n",
    "            image_bytes = blob.download_as_bytes()\n",
    "            image = open_image(image_bytes)\n",
    "            response = generate_text(image, prompt, mimeType)\n",
    "            #print('image_file_is:', blob)\n",
    "            #print(response)\n",
    "            responses.append(response)\n",
    "            file_names.append(blob.name)\n",
    "    return responses, file_names\n",
    "\n",
    "# Set mime type based on media type selection\n",
    "#mimeType = \"image/jpeg\"\n",
    "\n",
    "#prompt_text = \"Please identify the products in this image and return results in json format with Brand as an attribute\"\n",
    "\n",
    "# Generate text using Vertex AI, passing the mime type argument\n",
    "#generated_text = generate_text(B64_BASE_IMAGE, prompt_text, mimeType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a18184-d3ae-4cf8-88ee-76afa8c955d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_text = \"Please identify the products in this image\"\n",
    "responses, file_names = make_magic(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83d3a1d9-0b65-4bda-af49-fa4249fc3844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_df = pd.DataFrame(responses, columns=['llm_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa7556e9-aaa5-433d-9765-0bb044a485ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_names_df = pd.DataFrame(file_names, columns=['image_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9611e7e4-b87f-4752-9f01-fae03c3d80de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df = file_names_df.join(response_df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "185ea056-e15c-4e2a-859c-15a8690039a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df.to_csv('final_output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1cb34-d4d5-41ef-b837-908abd8bab8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
